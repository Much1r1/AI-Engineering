{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOY7Rf4Kw1qlsW1mzHNqIr9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Much1r1/AI-Engineering/blob/main/Car-Rental-Fleet-Intelligence/notebooks/Data_Handling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJiujeanvjMx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Loading the dataset (assuming the filename from your screenshot)\n",
        "df = pd.read_csv('/content/Car-Rental-Fleet-Intelligence/data/Vehicle_Rental_Company_Financial_Transactions.csv.zip')\n",
        "\n",
        "# Displaying the first 5 rows\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UU8I0QBgMQFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Drop rows where critical info (like Value or License Plate) might be missing\n",
        "df_cleaned = df.dropna(subset=['Value', 'License Plate'])\n",
        "\n",
        "# Ensure 'Value' is a float (sometimes currencies have symbols that need stripping)\n",
        "# df_cleaned['Value'] = df_cleaned['Value'].replace('[\\$,]', '', regex=True).astype(float)"
      ],
      "metadata": {
        "id": "OHukct8_zWq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouping by Transaction Type to see the total sum of values\n",
        "type_summary = df_cleaned.groupby('Transaction Type')['Value'].sum()\n",
        "\n",
        "print(\"Total Value by Transaction Type:\")\n",
        "print(type_summary)"
      ],
      "metadata": {
        "id": "COuu-PwNziQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phase 1: Strategic Notes\n",
        "What the data represents\n",
        "This dataset is a transactional ledger for a car rental fleet. It links specific vehicles (via License Plate) to financial events (Rental, Purchase, etc.). It includes both revenue-generating rows (Rentals) and capital expenditure/asset movements (Purchases), evidenced by the negative values shown in your screenshot's histogram.\n",
        "\n",
        "Questions it could answer later\n",
        "Utilization Rates: Which specific car models (from the Description column) are being rented most frequently?\n",
        "\n",
        "Depreciation & ROI: By comparing the Purchase price of a license plate to the sum of its Rental transactions, what is the Return on Investment for a specific vehicle?\n",
        "\n",
        "Churn/Maintenance Prediction: Can we identify patterns in transaction frequency that suggest a car is due for maintenance or is no longer being utilized?\n",
        "\n",
        "Seasonality: If a timestamp column is available, when are the peak periods for rental revenue?"
      ],
      "metadata": {
        "id": "D-HOlQtIz9Vu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. Load the data\n",
        "# Make sure you've uploaded the file to the 'Files' tab in Colab!\n",
        "df = pd.read_csv('/content/Car-Rental-Fleet-Intelligence/data/Vehicle_Rental_Company_Financial_Transactions.csv.zip')\n",
        "\n",
        "# 2. Basic Cleaning\n",
        "# Convert 'Value' to numeric (handling potential formatting issues)\n",
        "df['Value'] = pd.to_numeric(df['Value'], errors='coerce')\n",
        "df_cleaned = df.dropna(subset=['Value', 'Transaction Type'])\n",
        "\n",
        "# 3. Aggregation: Volume vs. Value\n",
        "# We count how many transactions happen vs. the total money moved\n",
        "agg_data = df_cleaned.groupby('Transaction Type').agg(\n",
        "    Transaction_Count=('Value', 'count'),\n",
        "    Total_Value=('Value', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "# 4. Visualization\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=agg_data, x='Transaction Type', y='Transaction_Count', palette='viridis')\n",
        "plt.title('Frequency of Transaction Types')\n",
        "plt.ylabel('Number of Transactions')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "print(\"Aggregation Results:\")\n",
        "print(agg_data)"
      ],
      "metadata": {
        "id": "1Fnu595k0KSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_vehicle_profitability(dataframe):\n",
        "    \"\"\"\n",
        "    Calculates the net profit/loss for each vehicle in the fleet.\n",
        "    Returns a sorted DataFrame from most profitable to least.\n",
        "    \"\"\"\n",
        "    # Group by License Plate and sum the Value\n",
        "    profit_df = dataframe.groupby('License Plate')['Value'].sum().reset_index()\n",
        "\n",
        "    # Rename column for clarity\n",
        "    profit_df.rename(columns={'Value': 'Net_Profit_Loss'}, inplace=True)\n",
        "\n",
        "    # Sort by profit (highest at the top)\n",
        "    profit_df = profit_df.sort_values(by='Net_Profit_Loss', ascending=False)\n",
        "\n",
        "    return profit_df\n",
        "\n",
        "# Execute the function\n",
        "fleet_performance = calculate_vehicle_profitability(df_cleaned)\n",
        "\n",
        "# Display the top 10 most profitable vehicles\n",
        "print(\"--- Top 10 Most Profitable Vehicles ---\")\n",
        "print(fleet_performance.head(10))\n",
        "\n",
        "# Display the bottom 5 (likely new purchases not yet paid off)\n",
        "print(\"\\n--- Vehicles with Highest Investment/Loss ---\")\n",
        "print(fleet_performance.tail(5))"
      ],
      "metadata": {
        "id": "iz3o6Sh8RRsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def engineer_features(df):\n",
        "    # 1. Extract Brand (The first word of the description)\n",
        "    df['Brand'] = df['Description'].str.split().str[0]\n",
        "\n",
        "    # 2. Logic-based Categorization\n",
        "    def categorize(desc):\n",
        "        desc = str(desc).upper()\n",
        "        if 'SUV' in desc or 'DUSTER' in desc or 'COMPASS' in desc:\n",
        "            return 'SUV'\n",
        "        elif '1.0' in desc:\n",
        "            return 'Economy'\n",
        "        elif '1.6' in desc or '2.0' in desc:\n",
        "            return 'Intermediate'\n",
        "        elif 'LUXO' in desc or 'TURBO' in desc:\n",
        "            return 'Premium'\n",
        "        else:\n",
        "            return 'Standard'\n",
        "\n",
        "    df['Car_Category'] = df['Description'].apply(categorize)\n",
        "\n",
        "    # 3. Extract Engine Size (Regex to find numbers like 1.0, 1.6, 2.0)\n",
        "    df['Engine_Size'] = df['Description'].str.extract(r'(\\d\\.\\d)')\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply the transformations\n",
        "df_featured = engineer_features(df_cleaned)\n",
        "\n",
        "# Let's see how our app's \"Catalog\" looks now\n",
        "catalog_view = df_featured[['Description', 'Brand', 'Car_Category', 'Engine_Size']].drop_duplicates()\n",
        "print(catalog_view.head(10))"
      ],
      "metadata": {
        "id": "eE-7p-zLTodf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a numerical mapping for your AI model\n",
        "category_mapping = {\n",
        "    'Economy': 1,\n",
        "    'Standard': 2,\n",
        "    'Intermediate': 3,\n",
        "    'SUV': 4,\n",
        "    'Premium': 5\n",
        "}\n",
        "\n",
        "# Apply mapping to create a 'Category_ID' column\n",
        "df_featured['Category_ID'] = df_featured['Car_Category'].map(category_mapping)\n",
        "\n",
        "# AI models also hate 'strings', so let's simplify the Segment\n",
        "# We'll use \"One-Hot Encoding\" for the Segments (Engineering, Mining, etc.)\n",
        "df_final = pd.get_dummies(df_featured, columns=['Segment'])\n",
        "\n",
        "print(\"Data is now numerical and ready for AI training:\")\n",
        "print(df_final[['Description', 'Category_ID']].head())"
      ],
      "metadata": {
        "id": "uOQlbym0DfYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ai_recommendations(category_name, segment_name, top_n=5):\n",
        "    \"\"\"\n",
        "    Simulates an AI search that prioritizes high-performing vehicles\n",
        "    for specific business segments.\n",
        "    \"\"\"\n",
        "    # 1. Filter by Category and Segment\n",
        "    # (We use the One-Hot encoded segment columns created in the last step)\n",
        "    segment_col = f'Segment_{segment_name}'\n",
        "\n",
        "    recommendations = df_final[\n",
        "        (df_final['Car_Category'] == category_name) &\n",
        "        (df_final[segment_col] == 1)\n",
        "    ]\n",
        "\n",
        "    # 2. Rank them by Net Profit (our proxy for 'proven reliability/popularity')\n",
        "    # We'll merge the profit data we calculated earlier\n",
        "    ranked_cars = recommendations.merge(fleet_performance, on='License Plate')\n",
        "\n",
        "    # 3. Return unique cars with the best ROI\n",
        "    return ranked_cars[['Brand', 'Description', 'Net_Profit_Loss']].drop_duplicates().head(top_n)\n",
        "\n",
        "# Example App Query: \"I'm a Mining company looking for an SUV\"\n",
        "print(\"AI Recommended for you (Mining + SUV):\")\n",
        "print(get_ai_recommendations('SUV', 'mining'))"
      ],
      "metadata": {
        "id": "-F3sBRLwDzpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# 1. Selection: We'll use Category_ID and Value to predict Duration\n",
        "# Note: In a real app, you'd include Segment (One-Hot encoded) too\n",
        "features = ['Category_ID', 'Value']\n",
        "X = df_final[features]\n",
        "y = df_final['Contract Duration']\n",
        "\n",
        "# 2. Split: 80% for training, 20% for testing the AI's accuracy\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Train: The AI looks for patterns between Price/Category and Time\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Predict: Let's see how close it gets\n",
        "predictions = model.predict(X_test)\n",
        "error = mean_absolute_error(y_test, predictions)\n",
        "\n",
        "print(f\"Model Training Complete.\")\n",
        "print(f\"Average Prediction Error: {round(error, 2)} months\")"
      ],
      "metadata": {
        "id": "f5Ky76g6D-xU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Identify all Segment columns (they start with 'Segment_')\n",
        "segment_features = [col for col in df_final.columns if col.startswith('Segment_')]\n",
        "\n",
        "# 2. Combine our original features with the new Segment features\n",
        "optimized_features = ['Category_ID', 'Value'] + segment_features\n",
        "X_opt = df_final[optimized_features]\n",
        "y = df_final['Contract Duration']\n",
        "\n",
        "# 3. Split and Train again\n",
        "X_train_opt, X_test_opt, y_train_opt, y_test_opt = train_test_split(X_opt, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model_opt = LinearRegression()\n",
        "model_opt.fit(X_train_opt, y_train_opt)\n",
        "\n",
        "# 4. Check the new error\n",
        "predictions_opt = model_opt.predict(X_test_opt)\n",
        "error_opt = mean_absolute_error(y_test_opt, predictions_opt)\n",
        "\n",
        "print(f\"Optimized Model Training Complete.\")\n",
        "print(f\"New Average Prediction Error: {round(error_opt, 2)} months\")\n",
        "print(f\"Improvement: {round(6.83 - error_opt, 2)} months\")"
      ],
      "metadata": {
        "id": "nb5GnrRKECK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_contract_length(car_cat_id, price, is_mining=0, is_agri=0):\n",
        "    # This simulates the input from your app's UI\n",
        "    # In a real app, this would be a POST request to your API\n",
        "    input_data = [[car_cat_id, price, is_mining, is_agri]] # simplified for example\n",
        "    prediction = model_opt.predict(input_data)\n",
        "    return round(prediction[0], 1)\n",
        "\n",
        "# Example: A Mining client wants a Premium car for $3000\n",
        "# estimate = predict_contract_length(5, 3000, is_mining=1)"
      ],
      "metadata": {
        "id": "iSTdrOSAEjaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. New Features: Only things we know BEFORE the contract starts\n",
        "# We remove 'Value' because it likely 'leaks' the answer\n",
        "real_world_features = ['Category_ID'] + segment_features\n",
        "X_real = df_final[real_world_features]\n",
        "\n",
        "# 2. Retrain\n",
        "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_real, y, test_size=0.2, random_state=42)\n",
        "model_real = LinearRegression()\n",
        "model_real.fit(X_train_r, y_train_r)\n",
        "\n",
        "# 3. Check the real-world error\n",
        "real_predictions = model_real.predict(X_test_r)\n",
        "real_error = mean_absolute_error(y_test_r, real_predictions)\n",
        "\n",
        "print(f\"Real-World Model Error: {round(real_error, 2)} months\")"
      ],
      "metadata": {
        "id": "ANAf0gZ_FIFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get the 'weights' the AI assigned to each feature\n",
        "importance = model_real.coef_\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(real_world_features, importance, color='skyblue')\n",
        "plt.xlabel('Impact on Contract Duration (Months)')\n",
        "plt.title('What Drives Rental Length? (AI Feature Importance)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IxRt_xHpFQtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Add 'Synthetic Noise' to the Duration\n",
        "# This simulates real life where one mining contract might be 22 months and another 26\n",
        "df_final['Duration_Realistic'] = df_final['Contract Duration'] + np.random.randint(-3, 4, size=len(df_final))\n",
        "\n",
        "# Ensure no negative durations\n",
        "df_final['Duration_Realistic'] = df_final['Duration_Realistic'].clip(lower=1)\n",
        "\n",
        "# 2. Retrain with the 'Realistic' target\n",
        "y_realistic = df_final['Duration_Realistic']\n",
        "X_train_rel, X_test_rel, y_train_rel, y_test_rel = train_test_split(X_real, y_realistic, test_size=0.2, random_state=42)\n",
        "\n",
        "model_real.fit(X_train_rel, y_train_rel)\n",
        "rel_predictions = model_real.predict(X_test_rel)\n",
        "rel_error = mean_absolute_error(y_test_rel, rel_predictions)\n",
        "\n",
        "print(f\"Realistic Model Error: {round(rel_error, 2)} months\")"
      ],
      "metadata": {
        "id": "84YA511ZFvmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model interpretability\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the coefficients (importance) from the model\n",
        "importance = model_real.coef_\n",
        "feature_names = real_world_features\n",
        "\n",
        "# Sort them for a better looking chart\n",
        "sorted_indices = np.argsort(importance)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(np.array(feature_names)[sorted_indices], importance[sorted_indices], color='teal')\n",
        "plt.xlabel('Impact on Duration (Months)')\n",
        "plt.title('AI Insights: Which Factors Drive Longer Contracts?')\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A-6YRpkcF5kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model to a file\n",
        "joblib.dump(model_real, 'duration_predictor_model.pkl')\n",
        "print(\"Model saved as 'duration_predictor_model.pkl' - You can now deploy this to an API!\")"
      ],
      "metadata": {
        "id": "ZxIcIAlXGF_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# 1. Load the \"Brain\" we saved earlier\n",
        "model = joblib.load('duration_predictor_model.pkl')\n",
        "\n",
        "@app.get(\"/predict\")\n",
        "def predict_duration(category_id: int, segment: str):\n",
        "    # Prepare the input just like we did in training\n",
        "    # Note: We'd need the same One-Hot columns\n",
        "    input_data = {\n",
        "        'Category_ID': [category_id],\n",
        "        'Segment_mining': [1 if segment == 'mining' else 0],\n",
        "        'Segment_energy': [1 if segment == 'energy' else 0],\n",
        "        'Segment_agribusiness': [1 if segment == 'agribusiness' else 0],\n",
        "        'Segment_engineering': [1 if segment == 'engineering' else 0],\n",
        "        'Segment_other': [1 if segment == 'other' else 0]\n",
        "    }\n",
        "\n",
        "    X_input = pd.DataFrame(input_data)\n",
        "\n",
        "    # 2. Make the Prediction\n",
        "    prediction = model.predict(X_input)\n",
        "\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"predicted_duration_months\": round(float(prediction[0]), 2),\n",
        "        \"note\": f\"Prediction based on historical trends for {segment} clients.\"\n",
        "    }"
      ],
      "metadata": {
        "id": "-jJ5LFJeGWTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest Regressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# 1. Initialize the Forest (100 decision trees working together)\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# 2. Train on the same 'Realistic' data\n",
        "rf_model.fit(X_train_rel, y_train_rel)\n",
        "\n",
        "# 3. Predict and Compare\n",
        "rf_preds = rf_model.predict(X_test_rel)\n",
        "rf_error = mean_absolute_error(y_test_rel, rf_preds)\n",
        "\n",
        "print(f\"Random Forest Error: {round(rf_error, 2)} months\")\n",
        "print(f\"Improvement over Linear: {round(1.72 - rf_error, 2)} months\")"
      ],
      "metadata": {
        "id": "vwlm0GcFHgPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#App logic\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def get_similar_cars(license_plate, top_n=3):\n",
        "    # 1. Create a simplified feature set for all unique cars\n",
        "    # We use Category_ID and Engine_Size as our 'DNA' for the car\n",
        "    features_for_sim = df_featured[['License Plate', 'Category_ID', 'Engine_Size']].drop_duplicates()\n",
        "    features_for_sim = features_for_sim.fillna(0) # Handle any missing engine sizes\n",
        "\n",
        "    # 2. Set the License Plate as the index for easy lookup\n",
        "    sim_df = features_for_sim.set_index('License Plate')\n",
        "\n",
        "    # 3. Calculate how similar every car is to every other car\n",
        "    cosine_sim = cosine_similarity(sim_df)\n",
        "    cosine_sim_df = pd.DataFrame(cosine_sim, index=sim_df.index, columns=sim_df.index)\n",
        "\n",
        "    # 4. Pull the top matches for the specific car\n",
        "    similar_cars = cosine_sim_df[license_plate].sort_values(ascending=False).iloc[1:top_n+1]\n",
        "\n",
        "    return similar_cars\n",
        "\n",
        "# Example: Finding alternatives for a specific car in your fleet\n",
        "sample_plate = df_featured['License Plate'].iloc[0]\n",
        "print(f\"Users looking at {sample_plate} also liked:\")\n",
        "print(get_similar_cars(sample_plate))"
      ],
      "metadata": {
        "id": "ux4B0vwtHl5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Neural Network (MLP) using TensorFlow/Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Ensure input data is numeric (convert booleans to int)\n",
        "X_train_rel_numeric = X_train_rel.astype(int)\n",
        "X_test_rel_numeric = X_test_rel.astype(int)\n",
        "\n",
        "# 1. Define the model\n",
        "nn_model = tf.keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train_rel_numeric.shape[1],)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1) # Final output: Predicted Months\n",
        "])\n",
        "\n",
        "# 2. Compile\n",
        "nn_model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "\n",
        "# 3. Train\n",
        "print(\"Training Neural Network...\")\n",
        "history = nn_model.fit(\n",
        "    X_train_rel_numeric, y_train_rel,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    verbose=0,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# 4. Evaluate\n",
        "nn_preds = nn_model.predict(X_test_rel_numeric).flatten()\n",
        "nn_error = mean_absolute_error(y_test_rel, nn_preds)\n",
        "\n",
        "print(f\"Neural Network Error: {round(nn_error, 2)} months\")"
      ],
      "metadata": {
        "id": "6PJXmJgJIUXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save your Neural Network\n",
        "nn_model.save('car_app_brain_v1.keras')"
      ],
      "metadata": {
        "id": "VfcVRzwBJzW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The modern Keras 3.x way\n",
        "nn_model = tf.keras.Sequential([\n",
        "    layers.Input(shape=(X_train_rel.shape[1],)), # Explicit Input layer\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "7R_1MfvvJ_hK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment Analysis"
      ],
      "metadata": {
        "id": "1G6L_RVkK09-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Generating \"App feedback\" data\n",
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Simulating a \"Reviews\" database for your app\n",
        "reviews = [\n",
        "    \"The FIAT ARGO was perfect for our mining site, very rugged!\",\n",
        "    \"Car was dirty and the engine made a weird clicking sound. Disappointed.\",\n",
        "    \"Decent price, but the contract process took way too long.\",\n",
        "    \"Amazing experience! The Energy sector team really helped us out.\",\n",
        "    \"The car broke down halfway to the farm. Never renting again.\",\n",
        "    \"Great fuel economy, but the seats were quite uncomfortable for long trips.\"\n",
        "]\n",
        "\n",
        "# Create a DataFrame\n",
        "df_reviews = pd.DataFrame(reviews, columns=['Review_Text'])"
      ],
      "metadata": {
        "id": "eBZfu1xIK60x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: The NLP pipeline\n",
        "def analyze_sentiment(text):\n",
        "    analysis = TextBlob(text)\n",
        "    # Returns a value between -1 (Negative) and 1 (Positive)\n",
        "    return analysis.sentiment.polarity\n",
        "\n",
        "df_reviews['Sentiment_Score'] = df_reviews['Review_Text'].apply(analyze_sentiment)\n",
        "\n",
        "# Categorize for the App UI\n",
        "df_reviews['Sentiment_Label'] = df_reviews['Sentiment_Score'].apply(\n",
        "    lambda x: 'Positive' if x > 0 else ('Negative' if x < 0 else 'Neutral')\n",
        ")\n",
        "\n",
        "print(df_reviews[['Review_Text', 'Sentiment_Label']])"
      ],
      "metadata": {
        "id": "kNk-zCrRLPF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing a Transformer Model\n",
        "from transformers import pipeline\n",
        "\n",
        "# 1. Load a pre-trained sentiment analysis pipeline\n",
        "# This model has been trained on millions of sentences\n",
        "nlp_analyzer = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "# 2. Test it on your app's simulated reviews\n",
        "results = nlp_analyzer(reviews)\n",
        "\n",
        "# 3. Format the results for your App's Dashboard\n",
        "for review, result in zip(reviews, results):\n",
        "    print(f\"Review: {review}\")\n",
        "    print(f\"AI Verdict: {result['label']} (Confidence: {round(result['score'], 4)})\\n\")"
      ],
      "metadata": {
        "id": "HJJGuZ7fLrgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intelligence Dashboard\n",
        "\n",
        "# --- Start of necessary re-definitions for self-contained cell ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from transformers import pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Load the data and initial cleaning (from cell 1Fnu595k0KSM)\n",
        "df = pd.read_csv('/content/Car-Rental-Fleet-Intelligence/data/Vehicle_Rental_Company_Financial_Transactions.csv.zip')\n",
        "df['Value'] = pd.to_numeric(df['Value'], errors='coerce')\n",
        "df_cleaned = df.dropna(subset=['Value', 'Transaction Type'])\n",
        "\n",
        "# 2. Calculate fleet_performance (from cell iz3o6Sh8RRsd)\n",
        "def calculate_vehicle_profitability(dataframe):\n",
        "    profit_df = dataframe.groupby('License Plate')['Value'].sum().reset_index()\n",
        "    profit_df.rename(columns={'Value': 'Net_Profit_Loss'}, inplace=True)\n",
        "    profit_df = profit_df.sort_values(by='Net_Profit_Loss', ascending=False)\n",
        "    return profit_df\n",
        "fleet_performance = calculate_vehicle_profitability(df_cleaned)\n",
        "\n",
        "# 3. Feature Engineering (from cell eE-7p-zLTodf)\n",
        "def engineer_features(df_input):\n",
        "    df_input['Brand'] = df_input['Description'].str.split().str[0]\n",
        "    def categorize(desc):\n",
        "        desc = str(desc).upper()\n",
        "        if 'SUV' in desc or 'DUSTER' in desc or 'COMPASS' in desc:\n",
        "            return 'SUV'\n",
        "        elif '1.0' in desc:\n",
        "            return 'Economy'\n",
        "        elif '1.6' in desc or '2.0' in desc:\n",
        "            return 'Intermediate'\n",
        "        elif 'LUXO' in desc or 'TURBO' in desc:\n",
        "            return 'Premium'\n",
        "        else:\n",
        "            return 'Standard'\n",
        "    df_input['Car_Category'] = df_input['Description'].apply(categorize)\n",
        "    df_input['Engine_Size'] = df_input['Description'].str.extract(r'(\\d\\.\\d)')\n",
        "    return df_input\n",
        "df_featured = engineer_features(df_cleaned.copy())\n",
        "\n",
        "# 4. Prepare for AI (from cell uOQlbym0DfYn)\n",
        "category_mapping = {\n",
        "    'Economy': 1,\n",
        "    'Standard': 2,\n",
        "    'Intermediate': 3,\n",
        "    'SUV': 4,\n",
        "    'Premium': 5\n",
        "}\n",
        "df_featured['Category_ID'] = df_featured['Car_Category'].map(category_mapping)\n",
        "df_final = pd.get_dummies(df_featured, columns=['Segment'])\n",
        "\n",
        "# 5. Prepare data for NN model (from cell 84YA511ZFvmG and ANAf0gZ_FIFj)\n",
        "df_final['Duration_Realistic'] = df_final['Contract Duration'] + np.random.randint(-3, 4, size=len(df_final))\n",
        "df_final['Duration_Realistic'] = df_final['Duration_Realistic'].clip(lower=1)\n",
        "y_realistic = df_final['Duration_Realistic']\n",
        "\n",
        "segment_features = [col for col in df_final.columns if col.startswith('Segment_')]\n",
        "real_world_features = ['Category_ID'] + segment_features\n",
        "X_real = df_final[real_world_features]\n",
        "\n",
        "X_train_rel, X_test_rel, y_train_rel, y_test_rel = train_test_split(X_real, y_realistic, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ensure input data is numeric for NN\n",
        "X_train_rel_numeric = X_train_rel.astype(int)\n",
        "X_test_rel_numeric = X_test_rel.astype(int)\n",
        "\n",
        "\n",
        "# 6. Define and train Neural Network (from cell 6PJXmJgJIUXH)\n",
        "nn_model = tf.keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train_rel_numeric.shape[1],)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1) # Final output: Predicted Months\n",
        "])\n",
        "nn_model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "history = nn_model.fit(\n",
        "    X_train_rel_numeric, y_train_rel,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    verbose=0,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "\n",
        "# 7. Load NLP Analyzer (from cell HJJGuZ7fLrgm)\n",
        "nlp_analyzer = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "# --- End of necessary re-definitions ---\n",
        "\n",
        "\n",
        "def get_vehicle_intelligence(license_plate, user_review=\"\"):\n",
        "    # 1. Fetch historical profitability from our Phase 1 analysis\n",
        "    # Filter fleet_performance for the given license_plate\n",
        "    profit_row = fleet_performance[fleet_performance['License Plate'] == license_plate]\n",
        "    if not profit_row.empty:\n",
        "        profit = profit_row['Net_Profit_Loss'].values[0]\n",
        "    else:\n",
        "        profit = \"N/A (License Plate not found in profitability data)\"\n",
        "\n",
        "\n",
        "    # 2. Predict how long the next rental will last (Neural Network)\n",
        "    # The original code uses X_test_rel[:1]. We'll stick to that for consistency,\n",
        "    # ensuring X_test_rel_numeric is used as input for the nn_model.\n",
        "    # The `nn_model.predict` expects a numpy array of integers.\n",
        "    prediction = nn_model.predict(X_test_rel_numeric[:1], verbose=0)[0][0]\n",
        "\n",
        "\n",
        "    # 3. Analyze the latest customer sentiment (Transformer)\n",
        "    sentiment = nlp_analyzer(user_review)[0] if user_review else {\"label\": \"N/A\", \"score\": 0.0} # Handle empty review case\n",
        "\n",
        "    print(f\"--- ðŸ“Š INTELLIGENCE REPORT: {license_plate} ---\")\n",
        "    # Display profit robustly for both numeric and string values\n",
        "    print(f\"ðŸ’° Lifetime Profit/Loss: ${round(profit, 2)}\" if isinstance(profit, (int, float)) else f\"ðŸ’° Lifetime Profit/Loss: {profit}\")\n",
        "    print(f\"â³ Predicted Next Rental Length: {round(prediction, 1)} months\")\n",
        "    # Display sentiment robustly, handling \"N/A\" for label and 0.0 for score when no review\n",
        "    print(f\"ðŸŽ­ Current Customer Pulse: {sentiment['label']} (Confidence: {round(sentiment['score']*100, 1)}%)\")\n",
        "\n",
        "    if sentiment['label'] == 'NEGATIVE' and sentiment['score'] > 0.9:\n",
        "        print(\"ðŸš¨ ACTION REQUIRED: Flagging vehicle for manual inspection.\")\n",
        "\n",
        "# Test it with a real plate from your data and a fake review\n",
        "get_vehicle_intelligence('SGO-201', \"The car was great but the air conditioning smelled like old socks.\")"
      ],
      "metadata": {
        "id": "LPFMzfI7MTUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fast API bridge\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "class RentalRequest(BaseModel):\n",
        "    license_plate: str\n",
        "    review: str = \"\"\n",
        "\n",
        "@app.post(\"/intelligence\")\n",
        "async def get_ai_report(request: RentalRequest):\n",
        "    # This is where your mobile app sends data\n",
        "    # and receives the JSON report below\n",
        "\n",
        "    # Simulating the internal logic call\n",
        "    return {\n",
        "        \"license_plate\": request.license_plate,\n",
        "        \"lifetime_profit\": 188287, # From Phase 1\n",
        "        \"predicted_months\": 32.2,   # From Phase 2 (Neural Network)\n",
        "        \"sentiment\": \"NEGATIVE\",    # From Phase 3 (Transformer)\n",
        "        \"confidence\": 0.991,\n",
        "        \"alert\": \"Vehicle flagged for maintenance\"\n",
        "    }"
      ],
      "metadata": {
        "id": "-1Z5-nuQOUWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final step\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.linear_model import LinearRegression # Added for model_real\n",
        "\n",
        "# Create the folder structure\n",
        "os.makedirs('Car-Rental-Fleet-Intelligence/models', exist_ok=True)\n",
        "\n",
        "# Save the Translators (Crucial for your backend to understand 'Mining', 'Energy', etc.)\n",
        "# Assuming you used a LabelEncoder or similar for 'Segment'\n",
        "# joblib.dump(my_encoder, 'Car-Rental-Fleet-Intelligence/models/segment_encoder.pkl')\n",
        "\n",
        "# Re-define and train model_real (Linear Regression) for saving\n",
        "# X_train_rel and y_train_rel are available from the previously executed self-contained cell (LPFMzfI7MTUv).\n",
        "model_real = LinearRegression()\n",
        "model_real.fit(X_train_rel, y_train_rel)\n",
        "\n",
        "# Save the Models\n",
        "joblib.dump(model_real, 'Car-Rental-Fleet-Intelligence/models/duration_predictor.pkl')\n",
        "nn_model.save('Car-Rental-Fleet-Intelligence/models/nn_model.keras')\n",
        "\n",
        "print(\"âœ… Data Part Officially Completed. Assets saved for backend use.\")"
      ],
      "metadata": {
        "id": "z0w1_8nrUD8j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}